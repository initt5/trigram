{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b381c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "023a7434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bbf7ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5009eb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)} # Characters to indexes\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()} # Indexes to characters\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3b42b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################### Bigram ####################################################################################\n",
    "\n",
    "# Split data set\n",
    "train_data, dev_data, test_data = random_split(words, [0.8, 0.1, 0.1], generator=g)\n",
    "X_train, y_train = [], []\n",
    "def split_data(data):\n",
    "    X, y = [], []\n",
    "    for w in data:\n",
    "        chs = ['.'] + list(w) + ['.']\n",
    "        for ch1, ch2 in zip(chs, chs[1:]):\n",
    "            X.append(stoi[ch1])\n",
    "            y.append(stoi[ch2])\n",
    "    X = torch.tensor(X)\n",
    "    y = torch.tensor(y)\n",
    "    return [X, y]\n",
    "\n",
    "# Create train, dev and test sets\n",
    "X_train, y_train = split_data(train_data)\n",
    "X_dev, y_dev = split_data(dev_data)\n",
    "X_test, y_test = split_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f160047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a914f0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 3.6793460845947266\n",
      "Epoch: 10 loss: 2.685643196105957\n",
      "Epoch: 20 loss: 2.571347713470459\n",
      "Epoch: 30 loss: 2.5294389724731445\n",
      "Epoch: 40 loss: 2.5084228515625\n",
      "Epoch: 50 loss: 2.496042251586914\n"
     ]
    }
   ],
   "source": [
    "n = X_train.nelement()\n",
    "Xenc = F.one_hot(X_train, num_classes=27).float()\n",
    "for epoch in range(50):\n",
    "    # forward pass\n",
    "    logits = Xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "    loss = -probs[torch.arange(n), y_train].log().mean()\n",
    "    \n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    W.data += -50 * W.grad\n",
    "    if (epoch == 0 or ((epoch+1)%10) == 0):\n",
    "        print(f'Epoch: {epoch+1} loss: {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72c3d37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_dev.nelement()\n",
    "# Loss on dev set\n",
    "Xenc = F.one_hot(X_dev, num_classes=27).float()\n",
    "logits = Xenc @ W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "loss = -probs[torch.arange(n), y_dev].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1805f373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4942, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d20c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_test.nelement()\n",
    "# Loss on test set\n",
    "Xenc = F.one_hot(X_test, num_classes=27).float()\n",
    "logits = Xenc @ W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "loss = -probs[torch.arange(n), y_test].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b255691b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4929, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f5ac706",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################### Trigram ###################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2edcf830",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################# 1x54 vector approach ############################################################################\n",
    "# Split data set\n",
    "train_data, dev_data, test_data = random_split(words, [0.8, 0.1, 0.1], generator=g)\n",
    "X_train, y_train = [], []\n",
    "def split_data(data):\n",
    "    X, y = [], []\n",
    "    for w in data:\n",
    "        chs = ['.'] + ['.'] + list(w) + ['.']\n",
    "        for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "            X.append((stoi[ch1], stoi[ch2]))\n",
    "            y.append(stoi[ch3])\n",
    "    return [X, y]\n",
    "\n",
    "# Create train, dev and test sets\n",
    "X_train, y_train = split_data(train_data)\n",
    "X_dev, y_dev = split_data(dev_data)\n",
    "X_test, y_test = split_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8604fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((54, 27), requires_grad=True, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d10d008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(X):\n",
    "    n = len(X)\n",
    "    Xenc = torch.zeros((n, 54))\n",
    "    for i in range(n):\n",
    "        vector = torch.zeros(54,)\n",
    "        ix1 = X[i][0]\n",
    "        ix2 = X[i][1]\n",
    "        vector[ix1] += 1\n",
    "        vector[27+ix2] += 1\n",
    "        Xenc[i] = vector\n",
    "    return Xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "091149a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xenc = one_hot_encode(X_train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53df727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(W, epochs, lmbda, lr, tune_mode=False):\n",
    "    n = len(X_train)\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        logits = Xenc @ W\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(1, keepdims=True)\n",
    "        loss = -probs[torch.arange(n), y_train].log().mean() + lmbda*(W**2).mean()\n",
    "\n",
    "        # Backward pass\n",
    "        W.grad = None\n",
    "        loss.backward()\n",
    "\n",
    "        # Update\n",
    "        W.data += -lr * W.grad\n",
    "\n",
    "        if (tune_mode == False and (epoch == 0 or ((epoch+1)%10) == 0)):\n",
    "            print(f'Epoch: {epoch+1} train loss: {loss}')\n",
    "    if tune_mode:\n",
    "        print(f'Lambda: {lmbda}, train loss: {loss}')\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1dde8a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 0, train loss: 2.445704936981201\n",
      "Lambda: 0, dev loss: 2.384784698486328\n",
      "Lambda: 0.0001, train loss: 2.4304146766662598\n",
      "Lambda: 0.0001, dev loss: 2.370854616165161\n",
      "Lambda: 0.001, train loss: 2.426582098007202\n",
      "Lambda: 0.001, dev loss: 2.3677735328674316\n",
      "Lambda: 0.005, train loss: 2.429805040359497\n",
      "Lambda: 0.005, dev loss: 2.37105655670166\n",
      "Lambda: 0.01, train loss: 2.4355039596557617\n",
      "Lambda: 0.01, dev loss: 2.3764073848724365\n",
      "Lambda: 0.1, train loss: 2.509036064147949\n",
      "Lambda: 0.1, dev loss: 2.4410972595214844\n"
     ]
    }
   ],
   "source": [
    "# Get best l2 regularization rate\n",
    "for lmbda in [0, 0.0001, 0.001, 0.005, 0.01, 0.1]:\n",
    "    temp_W = W\n",
    "    train_model(temp_W, 100, lmbda, 50, True)\n",
    "    n = len(X_dev)\n",
    "    xenc = one_hot_encode(X_dev).float()\n",
    "    # Loss on dev set\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "    loss = -probs[torch.arange(n), y_dev].log().mean() + lmbda * (W**2).mean()\n",
    "    print(f'Lambda: {lmbda}, dev loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c330c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 train loss: 2.3771605491638184\n",
      "Epoch: 10 train loss: 2.3961644172668457\n",
      "Epoch: 20 train loss: 2.435573101043701\n",
      "Epoch: 30 train loss: 2.394252300262451\n",
      "Epoch: 40 train loss: 2.431835651397705\n",
      "Epoch: 50 train loss: 2.392531394958496\n",
      "Epoch: 60 train loss: 2.4297971725463867\n",
      "Epoch: 70 train loss: 2.3912127017974854\n",
      "Epoch: 80 train loss: 2.428421974182129\n",
      "Epoch: 90 train loss: 2.3902111053466797\n",
      "Epoch: 100 train loss: 2.42739200592041\n"
     ]
    }
   ],
   "source": [
    "W = train_model(W, 100, 0.001, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37b7eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(X_test)\n",
    "Xenc = one_hot_encode(X_test).float()\n",
    "# Loss on test set\n",
    "logits = Xenc @ W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "loss = -probs[torch.arange(n), y_test].log().mean() + 0.001 * (W**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98a7ee19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3775, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f57608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################# 1x729 vector approach ###########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b7ca6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data set\n",
    "train_data, dev_data, test_data = random_split(words, [0.8, 0.1, 0.1], generator=g)\n",
    "X_train, y_train = [], []\n",
    "def split_data(data):\n",
    "    X, y = [], []\n",
    "    for w in data:\n",
    "        chs = ['.'] + ['.'] + list(w) + ['.']\n",
    "        for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "            X.append(stoi[ch1] + 27 * stoi[ch2])\n",
    "            y.append(stoi[ch3])\n",
    "    X = torch.tensor(X)\n",
    "    y = torch.tensor(y)\n",
    "    return [X, y]\n",
    "\n",
    "# Create train, dev and test sets\n",
    "X_train, y_train = split_data(train_data)\n",
    "X_dev, y_dev = split_data(dev_data)\n",
    "X_test, y_test = split_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ca14fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((729, 27), requires_grad=True, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47f46e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xenc = F.one_hot(X_train, num_classes=729).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cedf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 3.744565725326538\n",
      "Epoch: 10 loss: 2.801985025405884\n",
      "Epoch: 20 loss: 2.596341133117676\n",
      "Epoch: 30 loss: 2.5863234996795654\n",
      "Epoch: 40 loss: 2.422994375228882\n",
      "Epoch: 50 loss: 2.4064154624938965\n",
      "Epoch: 60 loss: 2.3876593112945557\n",
      "Epoch: 70 loss: 2.4260802268981934\n",
      "Epoch: 80 loss: 2.3363711833953857\n"
     ]
    }
   ],
   "source": [
    "n = X_train.nelement()\n",
    "for epoch in range(100):\n",
    "    # Forward pass\n",
    "    logits = Xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "    loss = -probs[torch.arange(n), y_train].log().mean()\n",
    "    \n",
    "    # Backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update\n",
    "    W.data += -200 * W.grad\n",
    "    \n",
    "    if (epoch == 0 or ((epoch+1)%10) == 0):\n",
    "        print(f'Epoch: {epoch+1} loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f965887",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_test.nelement()\n",
    "Xenc = F.one_hot(X_test, num_classes=729).float()\n",
    "# Loss on test set\n",
    "logits = Xenc @ W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "loss = -probs[torch.arange(n), y_test].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f59374",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcedaad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
